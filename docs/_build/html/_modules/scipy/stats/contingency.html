
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>scipy.stats.contingency &#8212; fermi_stacking  documentation</title>
    <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/alabaster.css" />
    <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
    <script src="../../../_static/jquery.js"></script>
    <script src="../../../_static/underscore.js"></script>
    <script src="../../../_static/doctools.js"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
   
  <link rel="stylesheet" href="../../../_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <h1>Source code for scipy.stats.contingency</h1><div class="highlight"><pre>
<span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">Contingency table functions (:mod:`scipy.stats.contingency`)</span>
<span class="sd">============================================================</span>

<span class="sd">Functions for creating and analyzing contingency tables.</span>

<span class="sd">.. currentmodule:: scipy.stats.contingency</span>

<span class="sd">.. autosummary::</span>
<span class="sd">   :toctree: generated/</span>

<span class="sd">   chi2_contingency</span>
<span class="sd">   relative_risk</span>
<span class="sd">   crosstab</span>
<span class="sd">   association</span>

<span class="sd">   expected_freq</span>
<span class="sd">   margins</span>

<span class="sd">&quot;&quot;&quot;</span>


<span class="kn">from</span> <span class="nn">functools</span> <span class="kn">import</span> <span class="n">reduce</span>
<span class="kn">import</span> <span class="nn">math</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">.stats</span> <span class="kn">import</span> <span class="n">power_divergence</span>
<span class="kn">from</span> <span class="nn">._relative_risk</span> <span class="kn">import</span> <span class="n">relative_risk</span>
<span class="kn">from</span> <span class="nn">._crosstab</span> <span class="kn">import</span> <span class="n">crosstab</span>


<span class="n">__all__</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;margins&#39;</span><span class="p">,</span> <span class="s1">&#39;expected_freq&#39;</span><span class="p">,</span> <span class="s1">&#39;chi2_contingency&#39;</span><span class="p">,</span> <span class="s1">&#39;crosstab&#39;</span><span class="p">,</span>
           <span class="s1">&#39;association&#39;</span><span class="p">,</span> <span class="s1">&#39;relative_risk&#39;</span><span class="p">]</span>


<div class="viewcode-block" id="margins"><a class="viewcode-back" href="../../../fermi_stacking.html#fermi_stacking.fermi_stacking_module.margins">[docs]</a><span class="k">def</span> <span class="nf">margins</span><span class="p">(</span><span class="n">a</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Return a list of the marginal sums of the array `a`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    a : ndarray</span>
<span class="sd">        The array for which to compute the marginal sums.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    margsums : list of ndarrays</span>
<span class="sd">        A list of length `a.ndim`.  `margsums[k]` is the result</span>
<span class="sd">        of summing `a` over all axes except `k`; it has the same</span>
<span class="sd">        number of dimensions as `a`, but the length of each axis</span>
<span class="sd">        except axis `k` will be 1.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; a = np.arange(12).reshape(2, 6)</span>
<span class="sd">    &gt;&gt;&gt; a</span>
<span class="sd">    array([[ 0,  1,  2,  3,  4,  5],</span>
<span class="sd">           [ 6,  7,  8,  9, 10, 11]])</span>
<span class="sd">    &gt;&gt;&gt; from scipy.stats.contingency import margins</span>
<span class="sd">    &gt;&gt;&gt; m0, m1 = margins(a)</span>
<span class="sd">    &gt;&gt;&gt; m0</span>
<span class="sd">    array([[15],</span>
<span class="sd">           [51]])</span>
<span class="sd">    &gt;&gt;&gt; m1</span>
<span class="sd">    array([[ 6,  8, 10, 12, 14, 16]])</span>

<span class="sd">    &gt;&gt;&gt; b = np.arange(24).reshape(2,3,4)</span>
<span class="sd">    &gt;&gt;&gt; m0, m1, m2 = margins(b)</span>
<span class="sd">    &gt;&gt;&gt; m0</span>
<span class="sd">    array([[[ 66]],</span>
<span class="sd">           [[210]]])</span>
<span class="sd">    &gt;&gt;&gt; m1</span>
<span class="sd">    array([[[ 60],</span>
<span class="sd">            [ 92],</span>
<span class="sd">            [124]]])</span>
<span class="sd">    &gt;&gt;&gt; m2</span>
<span class="sd">    array([[[60, 66, 72, 78]]])</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">margsums</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">ranged</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">a</span><span class="o">.</span><span class="n">ndim</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">ranged</span><span class="p">:</span>
        <span class="n">marg</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">apply_over_axes</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="p">[</span><span class="n">j</span> <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="n">ranged</span> <span class="k">if</span> <span class="n">j</span> <span class="o">!=</span> <span class="n">k</span><span class="p">])</span>
        <span class="n">margsums</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">marg</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">margsums</span></div>


<span class="k">def</span> <span class="nf">expected_freq</span><span class="p">(</span><span class="n">observed</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Compute the expected frequencies from a contingency table.</span>

<span class="sd">    Given an n-dimensional contingency table of observed frequencies,</span>
<span class="sd">    compute the expected frequencies for the table based on the marginal</span>
<span class="sd">    sums under the assumption that the groups associated with each</span>
<span class="sd">    dimension are independent.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    observed : array_like</span>
<span class="sd">        The table of observed frequencies.  (While this function can handle</span>
<span class="sd">        a 1-D array, that case is trivial.  Generally `observed` is at</span>
<span class="sd">        least 2-D.)</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    expected : ndarray of float64</span>
<span class="sd">        The expected frequencies, based on the marginal sums of the table.</span>
<span class="sd">        Same shape as `observed`.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; from scipy.stats.contingency import expected_freq</span>
<span class="sd">    &gt;&gt;&gt; observed = np.array([[10, 10, 20],[20, 20, 20]])</span>
<span class="sd">    &gt;&gt;&gt; expected_freq(observed)</span>
<span class="sd">    array([[ 12.,  12.,  16.],</span>
<span class="sd">           [ 18.,  18.,  24.]])</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Typically `observed` is an integer array. If `observed` has a large</span>
    <span class="c1"># number of dimensions or holds large values, some of the following</span>
    <span class="c1"># computations may overflow, so we first switch to floating point.</span>
    <span class="n">observed</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">observed</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>

    <span class="c1"># Create a list of the marginal sums.</span>
    <span class="n">margsums</span> <span class="o">=</span> <span class="n">margins</span><span class="p">(</span><span class="n">observed</span><span class="p">)</span>

    <span class="c1"># Create the array of expected frequencies.  The shapes of the</span>
    <span class="c1"># marginal sums returned by apply_over_axes() are just what we</span>
    <span class="c1"># need for broadcasting in the following product.</span>
    <span class="n">d</span> <span class="o">=</span> <span class="n">observed</span><span class="o">.</span><span class="n">ndim</span>
    <span class="n">expected</span> <span class="o">=</span> <span class="n">reduce</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">multiply</span><span class="p">,</span> <span class="n">margsums</span><span class="p">)</span> <span class="o">/</span> <span class="n">observed</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">**</span> <span class="p">(</span><span class="n">d</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">expected</span>


<span class="k">def</span> <span class="nf">chi2_contingency</span><span class="p">(</span><span class="n">observed</span><span class="p">,</span> <span class="n">correction</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">lambda_</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Chi-square test of independence of variables in a contingency table.</span>

<span class="sd">    This function computes the chi-square statistic and p-value for the</span>
<span class="sd">    hypothesis test of independence of the observed frequencies in the</span>
<span class="sd">    contingency table [1]_ `observed`.  The expected frequencies are computed</span>
<span class="sd">    based on the marginal sums under the assumption of independence; see</span>
<span class="sd">    `scipy.stats.contingency.expected_freq`.  The number of degrees of</span>
<span class="sd">    freedom is (expressed using numpy functions and attributes)::</span>

<span class="sd">        dof = observed.size - sum(observed.shape) + observed.ndim - 1</span>


<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    observed : array_like</span>
<span class="sd">        The contingency table. The table contains the observed frequencies</span>
<span class="sd">        (i.e. number of occurrences) in each category.  In the two-dimensional</span>
<span class="sd">        case, the table is often described as an &quot;R x C table&quot;.</span>
<span class="sd">    correction : bool, optional</span>
<span class="sd">        If True, *and* the degrees of freedom is 1, apply Yates&#39; correction</span>
<span class="sd">        for continuity.  The effect of the correction is to adjust each</span>
<span class="sd">        observed value by 0.5 towards the corresponding expected value.</span>
<span class="sd">    lambda_ : float or str, optional</span>
<span class="sd">        By default, the statistic computed in this test is Pearson&#39;s</span>
<span class="sd">        chi-squared statistic [2]_.  `lambda_` allows a statistic from the</span>
<span class="sd">        Cressie-Read power divergence family [3]_ to be used instead.  See</span>
<span class="sd">        `power_divergence` for details.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    chi2 : float</span>
<span class="sd">        The test statistic.</span>
<span class="sd">    p : float</span>
<span class="sd">        The p-value of the test</span>
<span class="sd">    dof : int</span>
<span class="sd">        Degrees of freedom</span>
<span class="sd">    expected : ndarray, same shape as `observed`</span>
<span class="sd">        The expected frequencies, based on the marginal sums of the table.</span>

<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    contingency.expected_freq</span>
<span class="sd">    fisher_exact</span>
<span class="sd">    chisquare</span>
<span class="sd">    power_divergence</span>
<span class="sd">    barnard_exact</span>
<span class="sd">    boschloo_exact</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    An often quoted guideline for the validity of this calculation is that</span>
<span class="sd">    the test should be used only if the observed and expected frequencies</span>
<span class="sd">    in each cell are at least 5.</span>

<span class="sd">    This is a test for the independence of different categories of a</span>
<span class="sd">    population. The test is only meaningful when the dimension of</span>
<span class="sd">    `observed` is two or more.  Applying the test to a one-dimensional</span>
<span class="sd">    table will always result in `expected` equal to `observed` and a</span>
<span class="sd">    chi-square statistic equal to 0.</span>

<span class="sd">    This function does not handle masked arrays, because the calculation</span>
<span class="sd">    does not make sense with missing values.</span>

<span class="sd">    Like stats.chisquare, this function computes a chi-square statistic;</span>
<span class="sd">    the convenience this function provides is to figure out the expected</span>
<span class="sd">    frequencies and degrees of freedom from the given contingency table.</span>
<span class="sd">    If these were already known, and if the Yates&#39; correction was not</span>
<span class="sd">    required, one could use stats.chisquare.  That is, if one calls::</span>

<span class="sd">        chi2, p, dof, ex = chi2_contingency(obs, correction=False)</span>

<span class="sd">    then the following is true::</span>

<span class="sd">        (chi2, p) == stats.chisquare(obs.ravel(), f_exp=ex.ravel(),</span>
<span class="sd">                                     ddof=obs.size - 1 - dof)</span>

<span class="sd">    The `lambda_` argument was added in version 0.13.0 of scipy.</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    .. [1] &quot;Contingency table&quot;,</span>
<span class="sd">           https://en.wikipedia.org/wiki/Contingency_table</span>
<span class="sd">    .. [2] &quot;Pearson&#39;s chi-squared test&quot;,</span>
<span class="sd">           https://en.wikipedia.org/wiki/Pearson%27s_chi-squared_test</span>
<span class="sd">    .. [3] Cressie, N. and Read, T. R. C., &quot;Multinomial Goodness-of-Fit</span>
<span class="sd">           Tests&quot;, J. Royal Stat. Soc. Series B, Vol. 46, No. 3 (1984),</span>
<span class="sd">           pp. 440-464.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    A two-way example (2 x 3):</span>

<span class="sd">    &gt;&gt;&gt; from scipy.stats import chi2_contingency</span>
<span class="sd">    &gt;&gt;&gt; obs = np.array([[10, 10, 20], [20, 20, 20]])</span>
<span class="sd">    &gt;&gt;&gt; chi2_contingency(obs)</span>
<span class="sd">    (2.7777777777777777,</span>
<span class="sd">     0.24935220877729619,</span>
<span class="sd">     2,</span>
<span class="sd">     array([[ 12.,  12.,  16.],</span>
<span class="sd">            [ 18.,  18.,  24.]]))</span>

<span class="sd">    Perform the test using the log-likelihood ratio (i.e. the &quot;G-test&quot;)</span>
<span class="sd">    instead of Pearson&#39;s chi-squared statistic.</span>

<span class="sd">    &gt;&gt;&gt; g, p, dof, expctd = chi2_contingency(obs, lambda_=&quot;log-likelihood&quot;)</span>
<span class="sd">    &gt;&gt;&gt; g, p</span>
<span class="sd">    (2.7688587616781319, 0.25046668010954165)</span>

<span class="sd">    A four-way example (2 x 2 x 2 x 2):</span>

<span class="sd">    &gt;&gt;&gt; obs = np.array(</span>
<span class="sd">    ...     [[[[12, 17],</span>
<span class="sd">    ...        [11, 16]],</span>
<span class="sd">    ...       [[11, 12],</span>
<span class="sd">    ...        [15, 16]]],</span>
<span class="sd">    ...      [[[23, 15],</span>
<span class="sd">    ...        [30, 22]],</span>
<span class="sd">    ...       [[14, 17],</span>
<span class="sd">    ...        [15, 16]]]])</span>
<span class="sd">    &gt;&gt;&gt; chi2_contingency(obs)</span>
<span class="sd">    (8.7584514426741897,</span>
<span class="sd">     0.64417725029295503,</span>
<span class="sd">     11,</span>
<span class="sd">     array([[[[ 14.15462386,  14.15462386],</span>
<span class="sd">              [ 16.49423111,  16.49423111]],</span>
<span class="sd">             [[ 11.2461395 ,  11.2461395 ],</span>
<span class="sd">              [ 13.10500554,  13.10500554]]],</span>
<span class="sd">            [[[ 19.5591166 ,  19.5591166 ],</span>
<span class="sd">              [ 22.79202844,  22.79202844]],</span>
<span class="sd">             [[ 15.54012004,  15.54012004],</span>
<span class="sd">              [ 18.10873492,  18.10873492]]]]))</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">observed</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">observed</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">observed</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;All values in `observed` must be nonnegative.&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">observed</span><span class="o">.</span><span class="n">size</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;No data; `observed` has size 0.&quot;</span><span class="p">)</span>

    <span class="n">expected</span> <span class="o">=</span> <span class="n">expected_freq</span><span class="p">(</span><span class="n">observed</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">expected</span> <span class="o">==</span> <span class="mi">0</span><span class="p">):</span>
        <span class="c1"># Include one of the positions where expected is zero in</span>
        <span class="c1"># the exception message.</span>
        <span class="n">zeropos</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">nonzero</span><span class="p">(</span><span class="n">expected</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)))[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;The internally computed table of expected &quot;</span>
                         <span class="s2">&quot;frequencies has a zero element at </span><span class="si">%s</span><span class="s2">.&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">zeropos</span><span class="p">,))</span>

    <span class="c1"># The degrees of freedom</span>
    <span class="n">dof</span> <span class="o">=</span> <span class="n">expected</span><span class="o">.</span><span class="n">size</span> <span class="o">-</span> <span class="nb">sum</span><span class="p">(</span><span class="n">expected</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">+</span> <span class="n">expected</span><span class="o">.</span><span class="n">ndim</span> <span class="o">-</span> <span class="mi">1</span>

    <span class="k">if</span> <span class="n">dof</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="c1"># Degenerate case; this occurs when `observed` is 1D (or, more</span>
        <span class="c1"># generally, when it has only one nontrivial dimension).  In this</span>
        <span class="c1"># case, we also have observed == expected, so chi2 is 0.</span>
        <span class="n">chi2</span> <span class="o">=</span> <span class="mf">0.0</span>
        <span class="n">p</span> <span class="o">=</span> <span class="mf">1.0</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">dof</span> <span class="o">==</span> <span class="mi">1</span> <span class="ow">and</span> <span class="n">correction</span><span class="p">:</span>
            <span class="c1"># Adjust `observed` according to Yates&#39; correction for continuity.</span>
            <span class="c1"># Magnitude of correction no bigger than difference; see gh-13875</span>
            <span class="n">diff</span> <span class="o">=</span> <span class="n">expected</span> <span class="o">-</span> <span class="n">observed</span>
            <span class="n">direction</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sign</span><span class="p">(</span><span class="n">diff</span><span class="p">)</span>
            <span class="n">magnitude</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">minimum</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">diff</span><span class="p">))</span>
            <span class="n">observed</span> <span class="o">=</span> <span class="n">observed</span> <span class="o">+</span> <span class="n">magnitude</span> <span class="o">*</span> <span class="n">direction</span>

        <span class="n">chi2</span><span class="p">,</span> <span class="n">p</span> <span class="o">=</span> <span class="n">power_divergence</span><span class="p">(</span><span class="n">observed</span><span class="p">,</span> <span class="n">expected</span><span class="p">,</span>
                                   <span class="n">ddof</span><span class="o">=</span><span class="n">observed</span><span class="o">.</span><span class="n">size</span> <span class="o">-</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">dof</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                                   <span class="n">lambda_</span><span class="o">=</span><span class="n">lambda_</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">chi2</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">dof</span><span class="p">,</span> <span class="n">expected</span>


<span class="k">def</span> <span class="nf">association</span><span class="p">(</span><span class="n">observed</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s2">&quot;cramer&quot;</span><span class="p">,</span> <span class="n">correction</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">lambda_</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Calculates degree of association between two nominal variables.</span>

<span class="sd">    The function provides the option for computing one of three measures of</span>
<span class="sd">    association between two nominal variables from the data given in a 2d</span>
<span class="sd">    contingency table: Tschuprow&#39;s T, Pearson&#39;s Contingency Coefficient</span>
<span class="sd">    and Cramer&#39;s V.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    observed : array-like</span>
<span class="sd">        The array of observed values</span>
<span class="sd">    method : {&quot;cramer&quot;, &quot;tschuprow&quot;, &quot;pearson&quot;} (default = &quot;cramer&quot;)</span>
<span class="sd">        The association test statistic.</span>
<span class="sd">    correction : bool, optional</span>
<span class="sd">        Inherited from `scipy.stats.contingency.chi2_contingency()`</span>
<span class="sd">    lambda_ : float or str, optional</span>
<span class="sd">        Inherited from `scipy.stats.contingency.chi2_contingency()`</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    statistic : float</span>
<span class="sd">        Value of the test statistic</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    Cramer&#39;s V, Tschuprow&#39;s T and Pearson&#39;s Contingency Coefficient, all</span>
<span class="sd">    measure the degree to which two nominal or ordinal variables are related,</span>
<span class="sd">    or the level of their association. This differs from correlation, although</span>
<span class="sd">    many often mistakenly consider them equivalent. Correlation measures in</span>
<span class="sd">    what way two variables are related, whereas, association measures how</span>
<span class="sd">    related the variables are. As such, association does not subsume</span>
<span class="sd">    independent variables, and is rather a test of independence. A value of</span>
<span class="sd">    1.0 indicates perfect association, and 0.0 means the variables have no</span>
<span class="sd">    association.</span>

<span class="sd">    Both the Cramer&#39;s V and Tschuprow&#39;s T are extensions of the phi</span>
<span class="sd">    coefficient.  Moreover, due to the close relationship between the</span>
<span class="sd">    Cramer&#39;s V and Tschuprow&#39;s T the returned values can often be similar</span>
<span class="sd">    or even equivalent.  They are likely to diverge more as the array shape</span>
<span class="sd">    diverges from a 2x2.</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    .. [1] &quot;Tschuprow&#39;s T&quot;,</span>
<span class="sd">           https://en.wikipedia.org/wiki/Tschuprow&#39;s_T</span>
<span class="sd">    .. [2] Tschuprow, A. A. (1939)</span>
<span class="sd">           Principles of the Mathematical Theory of Correlation;</span>
<span class="sd">           translated by M. Kantorowitsch. W. Hodge &amp; Co.</span>
<span class="sd">    .. [3] &quot;Cramer&#39;s V&quot;, https://en.wikipedia.org/wiki/Cramer&#39;s_V</span>
<span class="sd">    .. [4] &quot;Nominal Association: Phi and Cramer&#39;s V&quot;,</span>
<span class="sd">           http://www.people.vcu.edu/~pdattalo/702SuppRead/MeasAssoc/NominalAssoc.html</span>
<span class="sd">    .. [5] Gingrich, Paul, &quot;Association Between Variables&quot;,</span>
<span class="sd">           http://uregina.ca/~gingrich/ch11a.pdf</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    An example with a 4x2 contingency table:</span>

<span class="sd">    &gt;&gt;&gt; from scipy.stats.contingency import association</span>
<span class="sd">    &gt;&gt;&gt; obs4x2 = np.array([[100, 150], [203, 322], [420, 700], [320, 210]])</span>

<span class="sd">    Pearson&#39;s contingency coefficient</span>
<span class="sd">    &gt;&gt;&gt; association(obs4x2, method=&quot;pearson&quot;)</span>
<span class="sd">    0.18303298140595667</span>

<span class="sd">    Cramer&#39;s V</span>

<span class="sd">    &gt;&gt;&gt; association(obs4x2, method=&quot;cramer&quot;)</span>
<span class="sd">    0.18617813077483678</span>

<span class="sd">    Tschuprow&#39;s T</span>

<span class="sd">    &gt;&gt;&gt; association(obs4x2, method=&quot;tschuprow&quot;)</span>
<span class="sd">    0.14146478765062995</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">arr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">observed</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">np</span><span class="o">.</span><span class="n">issubdtype</span><span class="p">(</span><span class="n">arr</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">integer</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;`observed` must be an integer array.&quot;</span><span class="p">)</span>

    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">arr</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">2</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;method only accepts 2d arrays&quot;</span><span class="p">)</span>

    <span class="n">chi2_stat</span> <span class="o">=</span> <span class="n">chi2_contingency</span><span class="p">(</span><span class="n">arr</span><span class="p">,</span> <span class="n">correction</span><span class="o">=</span><span class="n">correction</span><span class="p">,</span>
                                 <span class="n">lambda_</span><span class="o">=</span><span class="n">lambda_</span><span class="p">)</span>

    <span class="n">phi2</span> <span class="o">=</span> <span class="n">chi2_stat</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">/</span> <span class="n">arr</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
    <span class="n">n_rows</span><span class="p">,</span> <span class="n">n_cols</span> <span class="o">=</span> <span class="n">arr</span><span class="o">.</span><span class="n">shape</span>
    <span class="k">if</span> <span class="n">method</span> <span class="o">==</span> <span class="s2">&quot;cramer&quot;</span><span class="p">:</span>
        <span class="n">value</span> <span class="o">=</span> <span class="n">phi2</span> <span class="o">/</span> <span class="nb">min</span><span class="p">(</span><span class="n">n_cols</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">n_rows</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">method</span> <span class="o">==</span> <span class="s2">&quot;tschuprow&quot;</span><span class="p">:</span>
        <span class="n">value</span> <span class="o">=</span> <span class="n">phi2</span> <span class="o">/</span> <span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">((</span><span class="n">n_rows</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">n_cols</span> <span class="o">-</span> <span class="mi">1</span><span class="p">))</span>
    <span class="k">elif</span> <span class="n">method</span> <span class="o">==</span> <span class="s1">&#39;pearson&#39;</span><span class="p">:</span>
        <span class="n">value</span> <span class="o">=</span> <span class="n">phi2</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">phi2</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Invalid argument value: &#39;method&#39; argument must &quot;</span>
                         <span class="s2">&quot;be &#39;cramer&#39;, &#39;tschuprow&#39;, or &#39;pearson&#39;&quot;</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>
</pre></div>

          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="../../../index.html">fermi_stacking</a></h1>








<h3>Navigation</h3>
<p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../fermi_stacking.html">Fermi Stacking</a></li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../../../index.html">Documentation overview</a><ul>
  <li><a href="../../index.html">Module code</a><ul>
  </ul></li>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../../../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>$('#searchbox').show(0);</script>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2024, Chris Karwin.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 4.4.0</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.12</a>
      
    </div>

    

    
  </body>
</html>